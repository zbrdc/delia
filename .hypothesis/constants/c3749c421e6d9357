# file: /home/dan/git/delia/src/delia/backend_manager.py
# hypothesis_version: 6.148.7

[0.0, 5.0, 10.0, 300.0, 200, 4096, '/api/tags', '/health', '/v1/chat/completions', '/v1/models', '1.0', ':latest', 'Authorization', 'BackendConfig', 'GEMINI_API_KEY', 'Local LM Studio', 'Local Ollama', 'Local llama.cpp', 'Unknown Backend', '_', 'active_backend', 'api_key', 'auth', 'available', 'backend_added', 'backend_close_failed', 'backend_removed', 'backend_updated', 'backends', 'chat_endpoint', 'client_close_failed', 'coder', 'connect_timeout', 'context_limit', 'data', 'degraded', 'enabled', 'fallback_enabled', 'gemini', 'ggml-vocab', 'gpu_memory_limit_gb', 'health', 'health_check_cached', 'health_endpoint', 'healthy', 'id', 'llamacpp', 'lmstudio', 'load_balance', 'loaded', 'local', 'memory_buffer_gb', 'models', 'models_endpoint', 'moe', 'name', 'no_api_key', 'o1', 'ollama', 'prefer_local', 'priority', 'probe_error', 'provider', 'quick', 'r1', 'reason', 'routing', 'settings_load_failed', 'settings_loaded', 'settings_save_failed', 'settings_saved', 'status', 'system', 'think', 'thinking', 'timeout_seconds', 'tracking_enabled', 'type', 'unhealthy', 'unknown', 'url', 'value', 'version', 'w']